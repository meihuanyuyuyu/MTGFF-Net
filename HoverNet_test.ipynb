{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from data/monuseg\n",
      "Dataset loaded\n",
      "(1, 1000, 1000, 2)\n",
      "(1, 1000, 1000, 2)\n",
      "(1, 1000, 1000, 2)\n",
      "(1, 1000, 1000, 2)\n",
      "(1, 1000, 1000, 2)\n",
      "(1, 1000, 1000, 2)\n",
      "(1, 1000, 1000, 2)\n",
      "(1, 1000, 1000, 2)\n",
      "(1, 1000, 1000, 2)\n",
      "(1, 1000, 1000, 2)\n",
      "(1, 1000, 1000, 2)\n",
      "(1, 1000, 1000, 2)\n",
      "(1, 1000, 1000, 2)\n",
      "(1, 1000, 1000, 2)\n",
      "dice score:0.822466\n",
      "numpy_result/monuseg/1/HoverNetMoNuSeg_test_result/gts.npy\n",
      "numpy_result/monuseg/1/HoverNetMoNuSeg_test_result/preds.npy\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 13/14 [01:53<00:07,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pq       SQ       DQ      AJI  multi_pq+\n",
      "0.632608 0.767365 0.823303 0.655751   0.634868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [02:00<00:00,  8.64s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'monuseg'\n",
    "device = 'cuda'\n",
    "split_num = 1\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from Netlib.HoVerNetlib.config import hovernet_config\n",
    "from Netlib.HoVerNetlib.infer import HovernetInfer\n",
    "from Netlib.CDNetlib.tools.augmentation import MyCenterCrop\n",
    "from Netlib.HoVerNetlib.tools.dataset import HoverNetDataset_MoNuSeg\n",
    "\n",
    "arg = hovernet_config.HoverNetMoNuSeg(ds=dataset_name,device=device,ds_num=split_num)\n",
    "arg.img_size = [1000,1000]\n",
    "infer =HovernetInfer(arg)\n",
    "data = HoverNetDataset_MoNuSeg(arg.DATASET_FP,[1000,1000],tranfs=[MyCenterCrop((1000,1000))],train=False)\n",
    "\n",
    "preds = np.zeros((0,1000,1000,2),dtype=np.int32)\n",
    "for i in range(len(data)):\n",
    "    img = data[i][0].unsqueeze(0).to(device)\n",
    "    pred = infer(img)\n",
    "    print(pred.shape)\n",
    "    preds = np.concatenate((preds,pred),axis=0)\n",
    "\n",
    "pred_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/gts.npy'\n",
    "gts_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/preds.npy'\n",
    "if not os.path.exists(os.path.dirname(pred_path)):\n",
    "        os.makedirs(os.path.dirname(pred_path))\n",
    "if not os.path.exists(os.path.dirname(gts_path)):\n",
    "        os.makedirs(os.path.dirname(gts_path))\n",
    "\n",
    "\n",
    "from Netlib.HoVerNetlib.tools.utils import draw_instance_map\n",
    "from Netlib.HoVerNetlib.tools.metric import dice_score\n",
    "\n",
    "def print_metric(pred_path, true_path):\n",
    "        pred =np.load(pred_path)\n",
    "        target = np.load(true_path)\n",
    "        pred = torch.from_numpy(pred.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        target = torch.from_numpy(target.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        dice = dice_score(pred[..., 1], target[..., 1])\n",
    "        print(f\"dice score:{dice:.6f}\")\n",
    "\n",
    "np.save(pred_path,preds)\n",
    "cp = MyCenterCrop((1000,1000))\n",
    "\n",
    "gts = cp((data.labels))[0].permute(0,2,3,1).cpu().numpy()\n",
    "np.save(gts_path,gts)\n",
    "imgs = cp((data.imgs))[0]\n",
    "\n",
    "if not os.path.exists(arg.figure_dir+'/preds'):\n",
    "        print(\"not find the path\")\n",
    "        os.makedirs(arg.figure_dir+'/preds')\n",
    "\n",
    "draw_instance_map(imgs,preds,fp=arg.figure_dir+'/preds')\n",
    "print_metric(pred_path,gts_path)\n",
    "\n",
    "print(pred_path)\n",
    "print(gts_path)\n",
    "print(arg.CLASSES-1)\n",
    "os.system(f'python compute_metric/compute_stats.py --mode=seg_class --pred={pred_path} --true={gts_path} --class_num={arg.CLASSES-1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from data/cpm17\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "(1, 256, 256, 2)\n",
      "dice score:0.874094\n",
      "numpy_result/cpm/1/HoverNetCPM_test_result/gts.npy\n",
      "numpy_result/cpm/1/HoverNetCPM_test_result/preds.npy\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 29/32 [00:01<00:00, 26.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pq      SQ       DQ      AJI  multi_pq+\n",
      "0.664632 0.80368 0.825135 0.711334   0.667397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:01<00:00, 25.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'cpm'\n",
    "device = 'cuda'\n",
    "split_num = 1\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from Netlib.HoVerNetlib.config import hovernet_config\n",
    "from Netlib.HoVerNetlib.infer import HovernetInfer\n",
    "from Netlib.CDNetlib.tools.augmentation import MyCenterCrop\n",
    "from Netlib.HoVerNetlib.tools.dataset import HoverNetDataset_CPM\n",
    "\n",
    "arg = hovernet_config.HoverNetCPM(ds=dataset_name,device=device,ds_num=split_num)\n",
    "infer =HovernetInfer(arg)\n",
    "data = HoverNetDataset_CPM(arg.DATASET_FP,tranfs=[MyCenterCrop((256,256))],train=False)\n",
    "\n",
    "preds = np.zeros((0,256,256,2),dtype=np.int32)\n",
    "for i in range(len(data)):\n",
    "    img = data[i][0].unsqueeze(0).to(device)\n",
    "    pred = infer(img)\n",
    "    preds = np.concatenate((preds,pred),axis=0)\n",
    "\n",
    "pred_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/gts.npy'\n",
    "gts_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/preds.npy'\n",
    "if not os.path.exists(os.path.dirname(pred_path)):\n",
    "        os.makedirs(os.path.dirname(pred_path))\n",
    "if not os.path.exists(os.path.dirname(gts_path)):\n",
    "        os.makedirs(os.path.dirname(gts_path))\n",
    "\n",
    "\n",
    "from Netlib.HoVerNetlib.tools.utils import draw_instance_map\n",
    "from Netlib.HoVerNetlib.tools.metric import dice_score\n",
    "\n",
    "def print_metric(pred_path, true_path):\n",
    "        pred =np.load(pred_path)\n",
    "        target = np.load(true_path)\n",
    "        pred = torch.from_numpy(pred.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        target = torch.from_numpy(target.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        dice = dice_score(pred[..., 1], target[..., 1])\n",
    "        print(f\"dice score:{dice:.6f}\")\n",
    "\n",
    "np.save(pred_path,preds)\n",
    "\n",
    "gts = np.load('data/cpm17/test/labels.npy')\n",
    "np.save(gts_path,gts)\n",
    "imgs = torch.load('data/cpm17/test/imgs.pt')\n",
    "\n",
    "if not os.path.exists(arg.figure_dir+'/preds'):\n",
    "        print(\"not find the path\")\n",
    "        os.makedirs(arg.figure_dir+'/preds')\n",
    "\n",
    "draw_instance_map(imgs,preds,fp=arg.figure_dir+'/preds')\n",
    "print_metric(pred_path,gts_path)\n",
    "\n",
    "print(pred_path)\n",
    "print(gts_path)\n",
    "print(arg.CLASSES-1)\n",
    "os.system(f'python compute_metric/compute_stats.py --mode=seg_class --pred={pred_path} --true={gts_path} --class_num={arg.CLASSES-1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from data/DSB2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/scipy/ndimage/_measurements.py:1534: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  results = [sum(input * grids[dir].astype(float), labels, index) / normalizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([659, 439, 334, 558, 271, 414, 195, 652,  23, 409, 292, 111, 287, 324,\n",
      "        592, 390, 612, 648, 340, 615, 660, 108,   2, 223, 134, 495,  46,  15,\n",
      "        275, 498, 216, 132, 500, 163, 123, 452,  51, 341, 376, 370, 655,  24,\n",
      "        211,  80, 526, 496, 446, 385, 173, 548, 471, 561, 209, 305,  37, 551,\n",
      "        247, 588, 176, 604, 233, 189,  68, 333, 515,  42, 208, 139, 194,  69,\n",
      "        432, 627, 589, 295, 595, 465, 646,  34,  38, 383, 162,  57, 538,  64,\n",
      "        477, 613,  85, 605,   8, 213, 510, 293, 265, 261, 210, 481, 356, 408,\n",
      "        323, 583,  75, 528, 336, 621,  43, 235, 529, 568, 180, 114,  36, 364,\n",
      "        405, 620, 144, 351, 168, 472,  20, 120, 518, 177, 397, 142, 191, 278,\n",
      "        649, 299, 447, 463, 601, 519, 527,  56])\n",
      "dice score:0.896611\n",
      "numpy_result/dsb/1/HoverNetDSB_test_result/gts.npy\n",
      "numpy_result/dsb/1/HoverNetDSB_test_result/preds.npy\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 131/134 [00:11<00:00, 16.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pq       SQ       DQ      AJI  multi_pq+\n",
      "0.710686 0.846276 0.824751 0.743456   0.699107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:11<00:00, 11.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'dsb'\n",
    "device = 'cuda'\n",
    "split_num = 1\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from Netlib.HoVerNetlib.config import hovernet_config\n",
    "from Netlib.HoVerNetlib.infer import HovernetInfer\n",
    "from Netlib.CDNetlib.tools.augmentation import MyCenterCrop\n",
    "from Netlib.HoVerNetlib.tools.dataset import HoverNetDataset_DSB,Subset\n",
    "\n",
    "arg = hovernet_config.HoverNetDSB(ds=dataset_name,device=device,ds_num=split_num)\n",
    "infer =HovernetInfer(arg)\n",
    "data = HoverNetDataset_DSB(arg.DATASET_FP,tranfs=[MyCenterCrop((256,256))],train=True)\n",
    "\n",
    "preds = np.zeros((0,256,256,2),dtype=np.int32)\n",
    "for i in arg.TEST_SET_INDEX:\n",
    "    img = data[i][0].unsqueeze(0).to(device)\n",
    "    pred = infer(img)\n",
    "    preds = np.concatenate((preds,pred),axis=0)\n",
    "\n",
    "pred_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/gts.npy'\n",
    "gts_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/preds.npy'\n",
    "if not os.path.exists(os.path.dirname(pred_path)):\n",
    "        os.makedirs(os.path.dirname(pred_path))\n",
    "if not os.path.exists(os.path.dirname(gts_path)):\n",
    "        os.makedirs(os.path.dirname(gts_path))\n",
    "\n",
    "import PIL.Image as Image\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "from Netlib.HoVerNetlib.tools.utils import draw_instance_map\n",
    "from Netlib.HoVerNetlib.tools.metric import dice_score\n",
    "\n",
    "def print_metric(pred_path, true_path):\n",
    "        pred =np.load(pred_path)\n",
    "        target = np.load(true_path)\n",
    "        pred = torch.from_numpy(pred.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        target = torch.from_numpy(target.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        dice = dice_score(pred[..., 1], target[..., 1])\n",
    "        print(f\"dice score:{dice:.6f}\")\n",
    "cp = MyCenterCrop((256,256))\n",
    "np.save(pred_path,preds)\n",
    "print(arg.TEST_SET_INDEX)\n",
    "imgs = torch.zeros((0,3,256,256),dtype=torch.float32)\n",
    "gts = np.zeros((0,256,256,2),dtype=np.int32)\n",
    "\n",
    "for i in arg.TEST_SET_INDEX:\n",
    "    img = Image.open(os.path.join('data/DSB2018/train', data.data_dir[i], 'images', data.data_dir[i]+'.png')).convert('RGB')\n",
    "    img = pil_to_tensor(img).float() / 255\n",
    "    img = cp((img))[0]\n",
    "    instances = os.listdir(os.path.join( 'data/DSB2018/train',data.data_dir[i], \"masks\"))\n",
    "    instances.sort()\n",
    "    label = torch.zeros(2, img.shape[1], img.shape[2], dtype=torch.long)\n",
    "    for idx, ins in enumerate(instances):\n",
    "        mask = Image.open(os.path.join(data.train_dir, data.data_dir[i], \"masks\", ins))\n",
    "        mask = pil_to_tensor(mask).bool() * 1\n",
    "        mask = cp((mask))[0]\n",
    "        label[0][label[0]==0] += mask[0][label[0]==0] * (idx+1)\n",
    "        label[1][label[1]==0] += mask[0][label[1]==0].long()\n",
    "\n",
    "    imgs = torch.cat((imgs,img.unsqueeze(0)),0)\n",
    "    gts = np.concatenate((gts,label.permute(1,2,0).unsqueeze(0).cpu().numpy()),axis=0)\n",
    "\n",
    "np.save(gts_path,gts)\n",
    "\n",
    "if not os.path.exists(arg.figure_dir+'/preds'):\n",
    "        print(\"not find the path\")\n",
    "        os.makedirs(arg.figure_dir+'/preds')\n",
    "\n",
    "draw_instance_map(imgs,preds,fp=arg.figure_dir+'/preds')\n",
    "print_metric(pred_path,gts_path)\n",
    "\n",
    "print(pred_path)\n",
    "print(gts_path)\n",
    "print(arg.CLASSES-1)\n",
    "os.system(f'python compute_metric/compute_stats.py --mode=seg_class --pred={pred_path} --true={gts_path} --class_num={arg.CLASSES-1}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
