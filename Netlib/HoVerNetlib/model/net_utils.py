import torch.nn as nn
import torch
import numpy as np
from scipy import ndimage
from torchvision.utils import save_image

class DenseBlock(nn.Module):
    """Dense Block as defined in:
    Huang, Gao, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q. Weinberger. 
    "Densely connected convolutional networks." In Proceedings of the IEEE conference 
    on computer vision and pattern recognition, pp. 4700-4708. 2017.
    Only performs `valid` convolution.
    """

    def __init__(self, in_ch, unit_ksize, unit_ch, unit_count, split=1):
        super(DenseBlock, self).__init__()
        assert len(unit_ksize) == len(unit_ch), "Unbalance Unit Info"

        self.nr_unit = unit_count
        self.in_ch = in_ch
        self.unit_ch = unit_ch

        # ! For inference only so init values for batchnorm may not match tensorflow
        unit_in_ch = in_ch
        pad_vals = [v // 2 for v in unit_ksize]
        self.units = nn.ModuleList()
        for idx in range(unit_count):
            self.units.append(nn.Sequential(
                nn.BatchNorm2d(unit_in_ch, eps=1e-5),
                nn.ReLU(inplace=True),
                nn.Conv2d(
                    unit_in_ch,
                    unit_ch[0],
                    unit_ksize[0],
                    stride=1,
                    padding=pad_vals[0],
                    bias=False,
                ),
                nn.BatchNorm2d(unit_ch[0], eps=1e-5),
                nn.ReLU(inplace=True),
                nn.Conv2d(
                    unit_ch[0],
                    unit_ch[1],
                    unit_ksize[1],
                    stride=1,
                    padding=pad_vals[1],
                    bias=False,
                    groups=split,
                ),
            ))
            unit_in_ch += unit_ch[1]

        self.blk_bna = nn.Sequential(nn.BatchNorm2d(unit_in_ch, eps=1e-5), nn.ReLU(inplace=True))

    def out_ch(self):
        return self.in_ch + self.nr_unit * self.unit_ch[-1]

    def forward(self, prev_feat):
        for idx in range(self.nr_unit):
            new_feat = self.units[idx](prev_feat)
            prev_feat = torch.cat([prev_feat, new_feat], dim=1)
        prev_feat = self.blk_bna(prev_feat)

        return prev_feat


def remove_small_objects(pred, min_size=64, connectivity=1):
    """Remove connected components smaller than the specified size.

    This function is taken from skimage.morphology.remove_small_objects, but the warning
    is removed when a single label is provided. 

    Args:
        pred: input labelled array
        min_size: minimum size of instance in output array
        connectivity: The connectivity defining the neighborhood of a pixel. 
    
    Returns:
        out: output array with instances removed under min_size

    """
    out = pred

    if min_size == 0:  # shortcut for efficiency
        return out

    if out.dtype == bool:
        selem = ndimage.generate_binary_structure(pred.ndim, connectivity)
        ccs = np.zeros_like(pred, dtype=np.int32)
        ndimage.label(pred, selem, output=ccs)
    else:
        ccs = out

    try:
        component_sizes = np.bincount(ccs.ravel())
    except ValueError:
        raise ValueError(
            "Negative value labels are not supported. Try "
            "relabeling the input with `scipy.ndimage.label` or "
            "`skimage.morphology.label`."
        )

    too_small = component_sizes < min_size
    too_small_mask = too_small[ccs]
    out[too_small_mask] = 0

    return out

def get_bounding_box(img):
    """Get bounding box coordinate information."""
    rows = np.any(img, axis=1)
    cols = np.any(img, axis=0)
    rmin, rmax = np.where(rows)[0][[0, -1]]
    cmin, cmax = np.where(cols)[0][[0, -1]]
    # due to python indexing, need to add 1 to max
    # else accessing will be 1px in the box, not out
    rmax += 1
    cmax += 1
    return [rmin, rmax, cmin, cmax]

def val_np_tp_hv(pred_tp:torch.Tensor,gt_tp:torch.Tensor,pred_np:torch.Tensor,gt_np:torch.Tensor,fp):
    #多类别tp
    color = torch.tensor([[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 0, 1], [0, 1, 1]], dtype=torch.float32, device=pred_np.device)
    tp_pic =color[pred_tp].permute(2,0,1)
    tp_pic_gt = color[gt_tp].permute(2,0,1)
    #掩码np
    np_pic =color[pred_np].permute(2,0,1)
    gt_np[gt_np!=0] += 1
    np_pic_gt = color[gt_np].permute(2,0,1)
    np_pic =  np_pic + np_pic_gt
    save_image(torch.stack([tp_pic_gt,tp_pic,np_pic],dim=0),fp)



