{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into memory\n",
      "Finishing loading data\n",
      "dice score:0.812170\n",
      "numpy_result/monuseg/1/MTGFFMonuSeg3_test_result/gts.npy\n",
      "numpy_result/monuseg/1/MTGFFMonuSeg3_test_result/preds.npy\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 11/14 [00:01<00:00, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pq       SQ       DQ      AJI  multi_pq+\n",
      "0.640564 0.756217 0.846391 0.657801   0.649109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00,  7.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'monuseg'\n",
    "device = 'cuda'\n",
    "split_num = 1\n",
    "\n",
    "import torch\n",
    "import os \n",
    "import numpy as np\n",
    "from Netlib.CDNetlib.tools.augmentation import  MyCenterCrop\n",
    "from Netlib.MTGFFlib.tools.dataset import MtgffMonusegDataset\n",
    "from Netlib.MTGFFlib.config import mtgff_config\n",
    "from Netlib.MTGFFlib.model.GeneralizedRCNN import MTGFFNet\n",
    "\n",
    "arg = mtgff_config.MTGFFMonuSeg3(ds = dataset_name, device = device, ds_num = split_num)\n",
    "net = arg.model(\n",
    "    anchors=arg.anchor_wh.to(arg.device),\n",
    "    use_H_stain = arg.USE_H_STAIN,\n",
    "    backbone=arg.BACKBONE,\n",
    "    bottom_up=arg.BOTTOM_UP,\n",
    "    proposal_generator=arg.PROPAOSAL_GENERATOR,\n",
    "    stride=arg.STRIDE,\n",
    "    rpn_pos_threshold=arg.RPN_POS_THRESHOLD,\n",
    "    rpn_fraction_ratio=arg.RPN_FRACTION_RATIO,\n",
    "    nms_threshold=arg.NMS_THRESHOLD,\n",
    "    pre_nms_k=arg.PRE_NMS_K,\n",
    "    post_nms_k=arg.POST_NMS_K,\n",
    "    use_deform = arg.USE_DEFORM,\n",
    "    roi_head=arg.ROI_HEAD,\n",
    "    box_detection=arg.BOX_DETECTION,\n",
    "    expand=arg.EXPAND,\n",
    "    expand_ratio=arg.EXPAND_RATIO,\n",
    "    use_gt_box=arg.USE_GT_BOX,\n",
    "    roi_resolution=arg.ROI_RESOLUTION,\n",
    "    stage2_max_proposal=arg.STAGE2_MAX_PROPOSAL,\n",
    "    stage2_sample_ratio=arg.STAGE2_SAMPLE_RATIO,\n",
    "    box_weight=arg.BOX_WEIGHT,\n",
    "    roi_pos_threshold=arg.ROI_POS_THRESHOLD,\n",
    "    post_decttion_score_threshold=arg.POST_DETECTION_SCORE_THRESHOLD,\n",
    "    detection_per_img=arg.DETECTION_PER_IMG,\n",
    "    num_classes=arg.NUM_CLASSES,\n",
    "    use_semantic=arg.USE_SEMANTIC,\n",
    "    seg_stride=arg.SEG_STRIDE,\n",
    "    fuse_feature=arg.FUSE_FEATURE\n",
    ")\n",
    "net.load_state_dict(torch.load(arg.load_model_para))\n",
    "net.to(device=device)\n",
    "net.eval()\n",
    "data = MtgffMonusegDataset(arg.ROI_RESOLUTION,transfs=[MyCenterCrop((256,256))],train=False)\n",
    "cp = MyCenterCrop((256,256))\n",
    "preds = np.zeros((0,256,256,2))\n",
    "with torch.no_grad():\n",
    "    for i in range(len(data)):\n",
    "        imgs = data[i][0][None].to(device=device)\n",
    "        #print(imgs.shape,imgs.max(),imgs.min())\n",
    "        pred, _ = net(imgs)\n",
    "        pred = net.inference(pred,[256,256])\n",
    "        preds = np.concatenate([preds,pred],axis=0)\n",
    "pred_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/gts.npy'\n",
    "gts_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/preds.npy'\n",
    "from Netlib.HoVerNetlib.tools.utils import draw_instance_map\n",
    "from Netlib.HoVerNetlib.tools.metric import dice_score\n",
    "def print_metric(pred_path, true_path):\n",
    "        pred =np.load(pred_path)\n",
    "        target = np.load(true_path)\n",
    "        pred = torch.from_numpy(pred.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        target = torch.from_numpy(target.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        dice = dice_score(pred[..., 1], target[..., 1])\n",
    "        print(f\"dice score:{dice:.6f}\")\n",
    "#获取文件目录中的父目录路径：\n",
    "if not os.path.exists(os.path.dirname(pred_path)):\n",
    "        os.makedirs(os.path.dirname(pred_path))\n",
    "if not os.path.exists(os.path.dirname(gts_path)):\n",
    "        os.makedirs(os.path.dirname(gts_path))\n",
    "\n",
    "np.save(pred_path,preds)\n",
    "gts = cp((data.labels))[0].permute(0,2,3,1).cpu().numpy()\n",
    "np.save(gts_path,gts)\n",
    "imgs = cp((data.imgs))[0]\n",
    "if not os.path.exists(arg.figure_dir+'/preds'):\n",
    "        print(\"not find the path\")\n",
    "        os.makedirs(arg.figure_dir+'/preds')\n",
    "draw_instance_map(imgs,preds,fp=arg.figure_dir+'/preds')\n",
    "print_metric(pred_path,gts_path)\n",
    "\n",
    "print(pred_path)\n",
    "print(gts_path)\n",
    "print(arg.CLASSES-1)\n",
    "os.system(f'python compute_metric/compute_stats.py --mode=seg_class --pred={pred_path} --true={gts_path} --class_num={arg.CLASSES-1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from data/cpm17\n",
      "dice score:0.802530\n",
      "numpy_result/cpm/1/MTGFFCPM4_test_result/gts.npy\n",
      "numpy_result/cpm/1/MTGFFCPM4_test_result/preds.npy\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 29/32 [00:01<00:00, 27.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pq       SQ      DQ      AJI  multi_pq+\n",
      "0.591991 0.747234 0.78906 0.625328   0.591964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:01<00:00, 26.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'cpm'\n",
    "device = 'cuda'\n",
    "split_num = 1\n",
    "\n",
    "import torch\n",
    "import os \n",
    "import numpy as np\n",
    "from Netlib.CDNetlib.tools.augmentation import  MyCenterCrop\n",
    "from Netlib.MTGFFlib.tools.dataset import MtgffCPMDataset\n",
    "from Netlib.MTGFFlib.config import mtgff_config\n",
    "from Netlib.MTGFFlib.model.GeneralizedRCNN import MTGFFNet\n",
    "\n",
    "arg = mtgff_config.MTGFFCPM4(ds = dataset_name, device = device, ds_num = split_num)\n",
    "net = arg.model(\n",
    "    anchors=arg.anchor_wh.to(arg.device),\n",
    "    use_H_stain = arg.USE_H_STAIN,\n",
    "    backbone=arg.BACKBONE,\n",
    "    bottom_up=arg.BOTTOM_UP,\n",
    "    proposal_generator=arg.PROPAOSAL_GENERATOR,\n",
    "    stride=arg.STRIDE,\n",
    "    rpn_pos_threshold=arg.RPN_POS_THRESHOLD,\n",
    "    rpn_fraction_ratio=arg.RPN_FRACTION_RATIO,\n",
    "    nms_threshold=arg.NMS_THRESHOLD,\n",
    "    pre_nms_k=arg.PRE_NMS_K,\n",
    "    post_nms_k=arg.POST_NMS_K,\n",
    "    use_deform = arg.USE_DEFORM,\n",
    "    roi_head=arg.ROI_HEAD,\n",
    "    box_detection=arg.BOX_DETECTION,\n",
    "    expand=arg.EXPAND,\n",
    "    expand_ratio=arg.EXPAND_RATIO,\n",
    "    use_gt_box=arg.USE_GT_BOX,\n",
    "    roi_resolution=arg.ROI_RESOLUTION,\n",
    "    stage2_max_proposal=arg.STAGE2_MAX_PROPOSAL,\n",
    "    stage2_sample_ratio=arg.STAGE2_SAMPLE_RATIO,\n",
    "    box_weight=arg.BOX_WEIGHT,\n",
    "    roi_pos_threshold=arg.ROI_POS_THRESHOLD,\n",
    "    post_decttion_score_threshold=arg.POST_DETECTION_SCORE_THRESHOLD,\n",
    "    detection_per_img=arg.DETECTION_PER_IMG,\n",
    "    num_classes=arg.NUM_CLASSES,\n",
    "    use_semantic=arg.USE_SEMANTIC,\n",
    "    seg_stride=arg.SEG_STRIDE,\n",
    "    fuse_feature=arg.FUSE_FEATURE\n",
    ")\n",
    "net.load_state_dict(torch.load(arg.load_model_para))\n",
    "net.to(device=device)\n",
    "net.eval()\n",
    "data = MtgffCPMDataset(arg.DATASET_FP,arg.ROI_RESOLUTION,img_size=[256,256],transfs=[MyCenterCrop((256,256))],train=False)\n",
    "\n",
    "cp = MyCenterCrop((256,256))\n",
    "preds = np.zeros((0,256,256,2))\n",
    "with torch.no_grad():\n",
    "    for i in range(len(data)):\n",
    "        imgs = data[i][0][None].to(device=device)\n",
    "        #print(imgs.shape,imgs.max(),imgs.min())\n",
    "        pred, _ = net(imgs)\n",
    "        pred = net.inference(pred,[256,256])\n",
    "        preds = np.concatenate([preds,pred],axis=0)\n",
    "\n",
    "\n",
    "pred_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/gts.npy'\n",
    "gts_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/preds.npy'\n",
    "from Netlib.HoVerNetlib.tools.utils import draw_instance_map\n",
    "from Netlib.HoVerNetlib.tools.metric import dice_score\n",
    "\n",
    "def print_metric(pred_path, true_path):\n",
    "        pred =np.load(pred_path)\n",
    "        target = np.load(true_path)\n",
    "        pred = torch.from_numpy(pred.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        target = torch.from_numpy(target.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        dice = dice_score(pred[..., 1], target[..., 1])\n",
    "        print(f\"dice score:{dice:.6f}\")\n",
    "\n",
    "#获取文件目录中的父目录路径：\n",
    "if not os.path.exists(os.path.dirname(pred_path)):\n",
    "        os.makedirs(os.path.dirname(pred_path))\n",
    "if not os.path.exists(os.path.dirname(gts_path)):\n",
    "        os.makedirs(os.path.dirname(gts_path))\n",
    "\n",
    "np.save(pred_path,preds)\n",
    "\n",
    "gts = np.load('data/cpm17/test/labels.npy')\n",
    "np.save(gts_path,gts)\n",
    "imgs = torch.load('data/cpm17/test/imgs.pt')\n",
    "\n",
    "if not os.path.exists(arg.figure_dir+'/preds'):\n",
    "        print(\"not find the path\")\n",
    "        os.makedirs(arg.figure_dir+'/preds')\n",
    "\n",
    "draw_instance_map(imgs,preds,fp=arg.figure_dir+'/preds')\n",
    "print_metric(pred_path,gts_path)\n",
    "\n",
    "print(pred_path)\n",
    "print(gts_path)\n",
    "print(arg.CLASSES-1)\n",
    "os.system(f'python compute_metric/compute_stats.py --mode=seg_class --pred={pred_path} --true={gts_path} --class_num={arg.CLASSES-1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from data/DSB2018\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.5294, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 10 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.4078, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 13 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.6431, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 18 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3725, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 10 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8588, device='cuda:0') tensor(0.0353, device='cuda:0')\n",
      "(1, 256, 256, 2) 33 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 41 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3765, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 16 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8588, device='cuda:0') tensor(0., device='cuda:0')\n",
      "(1, 256, 256, 2) 106 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9294, device='cuda:0') tensor(0.2745, device='cuda:0')\n",
      "(1, 256, 256, 2) 2 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9882, device='cuda:0') tensor(0.0392, device='cuda:0')\n",
      "(1, 256, 256, 2) 41 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.2235, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 33 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3373, device='cuda:0') tensor(0., device='cuda:0')\n",
      "(1, 256, 256, 2) 3 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8392, device='cuda:0') tensor(0., device='cuda:0')\n",
      "(1, 256, 256, 2) 13 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3412, device='cuda:0') tensor(0.0196, device='cuda:0')\n",
      "(1, 256, 256, 2) 15 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9294, device='cuda:0') tensor(0.1020, device='cuda:0')\n",
      "(1, 256, 256, 2) 46 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3490, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 8 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.4275, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 6 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3647, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 11 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.1843, device='cuda:0')\n",
      "(1, 256, 256, 2) 6 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8392, device='cuda:0') tensor(0., device='cuda:0')\n",
      "(1, 256, 256, 2) 13 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.5608, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 31 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.1451, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 10 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9098, device='cuda:0') tensor(0.0588, device='cuda:0')\n",
      "(1, 256, 256, 2) 60 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3647, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 29 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3098, device='cuda:0') tensor(0., device='cuda:0')\n",
      "(1, 256, 256, 2) 10 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.4471, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 25 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.4039, device='cuda:0') tensor(0., device='cuda:0')\n",
      "(1, 256, 256, 2) 12 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0353, device='cuda:0')\n",
      "(1, 256, 256, 2) 26 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3451, device='cuda:0') tensor(0., device='cuda:0')\n",
      "(1, 256, 256, 2) 10 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.1451, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 11 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3569, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 6 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3961, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 12 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.1373, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 7 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3961, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 8 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3608, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 10 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.4314, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 33 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.6392, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 15 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.6863, device='cuda:0') tensor(0.0353, device='cuda:0')\n",
      "(1, 256, 256, 2) 10 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9059, device='cuda:0') tensor(0.0157, device='cuda:0')\n",
      "(1, 256, 256, 2) 8 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8000, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 33 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0392, device='cuda:0')\n",
      "(1, 256, 256, 2) 6 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.5843, device='cuda:0') tensor(0.0353, device='cuda:0')\n",
      "(1, 256, 256, 2) 7 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.1843, device='cuda:0')\n",
      "(1, 256, 256, 2) 2 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8471, device='cuda:0') tensor(0., device='cuda:0')\n",
      "(1, 256, 256, 2) 9 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0392, device='cuda:0')\n",
      "(1, 256, 256, 2) 82 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9412, device='cuda:0') tensor(0.0941, device='cuda:0')\n",
      "(1, 256, 256, 2) 29 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8392, device='cuda:0') tensor(0.0118, device='cuda:0')\n",
      "(1, 256, 256, 2) 64 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3765, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 1 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3176, device='cuda:0') tensor(0., device='cuda:0')\n",
      "(1, 256, 256, 2) 6 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.1608, device='cuda:0') tensor(0.0196, device='cuda:0')\n",
      "(1, 256, 256, 2) 11 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.1569, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 7 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.4275, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 55 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8471, device='cuda:0') tensor(0., device='cuda:0')\n",
      "(1, 256, 256, 2) 8 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.1882, device='cuda:0') tensor(0.0196, device='cuda:0')\n",
      "(1, 256, 256, 2) 11 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8549, device='cuda:0') tensor(0., device='cuda:0')\n",
      "(1, 256, 256, 2) 9 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0314, device='cuda:0')\n",
      "(1, 256, 256, 2) 13 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0353, device='cuda:0')\n",
      "(1, 256, 256, 2) 8 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0353, device='cuda:0')\n",
      "(1, 256, 256, 2) 17 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9059, device='cuda:0') tensor(0., device='cuda:0')\n",
      "(1, 256, 256, 2) 11 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0392, device='cuda:0')\n",
      "(1, 256, 256, 2) 10 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.2078, device='cuda:0') tensor(0.0157, device='cuda:0')\n",
      "(1, 256, 256, 2) 13 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.4157, device='cuda:0') tensor(0.0353, device='cuda:0')\n",
      "(1, 256, 256, 2) 0 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.6902, device='cuda:0') tensor(0.0392, device='cuda:0')\n",
      "(1, 256, 256, 2) 11 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.4902, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 47 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9333, device='cuda:0') tensor(0.0667, device='cuda:0')\n",
      "(1, 256, 256, 2) 39 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8549, device='cuda:0') tensor(0.0667, device='cuda:0')\n",
      "(1, 256, 256, 2) 63 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.5373, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 45 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9490, device='cuda:0') tensor(0.0824, device='cuda:0')\n",
      "(1, 256, 256, 2) 38 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.1529, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 8 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9647, device='cuda:0') tensor(0.2157, device='cuda:0')\n",
      "(1, 256, 256, 2) 13 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.2902, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 9 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8392, device='cuda:0') tensor(0.0431, device='cuda:0')\n",
      "(1, 256, 256, 2) 5 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8353, device='cuda:0') tensor(0.0392, device='cuda:0')\n",
      "(1, 256, 256, 2) 37 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.1647, device='cuda:0') tensor(0.0118, device='cuda:0')\n",
      "(1, 256, 256, 2) 12 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8902, device='cuda:0') tensor(0.0392, device='cuda:0')\n",
      "(1, 256, 256, 2) 15 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.4824, device='cuda:0') tensor(0.0392, device='cuda:0')\n",
      "(1, 256, 256, 2) 4 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.5529, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 36 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9843, device='cuda:0') tensor(0.0784, device='cuda:0')\n",
      "(1, 256, 256, 2) 48 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.6980, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 29 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9216, device='cuda:0') tensor(0.1176, device='cuda:0')\n",
      "(1, 256, 256, 2) 4 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.6078, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 38 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.1373, device='cuda:0') tensor(0.0118, device='cuda:0')\n",
      "(1, 256, 256, 2) 9 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.5059, device='cuda:0') tensor(0., device='cuda:0')\n",
      "(1, 256, 256, 2) 107 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0549, device='cuda:0')\n",
      "(1, 256, 256, 2) 61 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3059, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 6 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9569, device='cuda:0') tensor(0.0745, device='cuda:0')\n",
      "(1, 256, 256, 2) 45 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.1490, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 16 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3843, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 11 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0392, device='cuda:0')\n",
      "(1, 256, 256, 2) 15 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8431, device='cuda:0') tensor(0.0353, device='cuda:0')\n",
      "(1, 256, 256, 2) 23 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.5882, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 24 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3098, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 8 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3725, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 20 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9608, device='cuda:0') tensor(0.2000, device='cuda:0')\n",
      "(1, 256, 256, 2) 9 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8392, device='cuda:0') tensor(0.0588, device='cuda:0')\n",
      "(1, 256, 256, 2) 34 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.1686, device='cuda:0') tensor(0.0118, device='cuda:0')\n",
      "(1, 256, 256, 2) 8 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9333, device='cuda:0') tensor(0.0118, device='cuda:0')\n",
      "(1, 256, 256, 2) 10 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.4431, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 10 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0353, device='cuda:0')\n",
      "(1, 256, 256, 2) 20 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0392, device='cuda:0')\n",
      "(1, 256, 256, 2) 42 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.4667, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 24 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0353, device='cuda:0')\n",
      "(1, 256, 256, 2) 24 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.6431, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 45 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0392, device='cuda:0')\n",
      "(1, 256, 256, 2) 80 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.1608, device='cuda:0') tensor(0.0196, device='cuda:0')\n",
      "(1, 256, 256, 2) 11 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3412, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 12 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3216, device='cuda:0') tensor(0., device='cuda:0')\n",
      "(1, 256, 256, 2) 5 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.1294, device='cuda:0') tensor(0.0118, device='cuda:0')\n",
      "(1, 256, 256, 2) 11 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.2863, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 23 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0392, device='cuda:0')\n",
      "(1, 256, 256, 2) 52 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.1216, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 9 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3765, device='cuda:0') tensor(0.0314, device='cuda:0')\n",
      "(1, 256, 256, 2) 7 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0353, device='cuda:0')\n",
      "(1, 256, 256, 2) 14 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9059, device='cuda:0') tensor(0.1098, device='cuda:0')\n",
      "(1, 256, 256, 2) 34 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.4824, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 13 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.4235, device='cuda:0') tensor(0.0353, device='cuda:0')\n",
      "(1, 256, 256, 2) 1 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.1608, device='cuda:0') tensor(0.0157, device='cuda:0')\n",
      "(1, 256, 256, 2) 15 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.2980, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 23 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.3098, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 6 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.2353, device='cuda:0') tensor(0.0353, device='cuda:0')\n",
      "(1, 256, 256, 2) 6 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8588, device='cuda:0') tensor(0., device='cuda:0')\n",
      "(1, 256, 256, 2) 10 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9961, device='cuda:0') tensor(0.0902, device='cuda:0')\n",
      "(1, 256, 256, 2) 37 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9569, device='cuda:0') tensor(0.0392, device='cuda:0')\n",
      "(1, 256, 256, 2) 14 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.1922, device='cuda:0') tensor(0.0157, device='cuda:0')\n",
      "(1, 256, 256, 2) 12 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8471, device='cuda:0') tensor(0., device='cuda:0')\n",
      "(1, 256, 256, 2) 11 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0392, device='cuda:0')\n",
      "(1, 256, 256, 2) 84 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8627, device='cuda:0') tensor(0.0392, device='cuda:0')\n",
      "(1, 256, 256, 2) 18 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.7059, device='cuda:0') tensor(0.0078, device='cuda:0')\n",
      "(1, 256, 256, 2) 32 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.4118, device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 21 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.9412, device='cuda:0') tensor(0.0745, device='cuda:0')\n",
      "(1, 256, 256, 2) 17 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.1725, device='cuda:0') tensor(0.0157, device='cuda:0')\n",
      "(1, 256, 256, 2) 7 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0353, device='cuda:0')\n",
      "(1, 256, 256, 2) 63 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(1., device='cuda:0') tensor(0.0039, device='cuda:0')\n",
      "(1, 256, 256, 2) 12 0\n",
      "torch.Size([1, 3, 256, 256]) tensor(0.8471, device='cuda:0') tensor(0.0431, device='cuda:0')\n",
      "(1, 256, 256, 2) 36 0\n",
      "tensor([659, 439, 334, 558, 271, 414, 195, 652,  23, 409, 292, 111, 287, 324,\n",
      "        592, 390, 612, 648, 340, 615, 660, 108,   2, 223, 134, 495,  46,  15,\n",
      "        275, 498, 216, 132, 500, 163, 123, 452,  51, 341, 376, 370, 655,  24,\n",
      "        211,  80, 526, 496, 446, 385, 173, 548, 471, 561, 209, 305,  37, 551,\n",
      "        247, 588, 176, 604, 233, 189,  68, 333, 515,  42, 208, 139, 194,  69,\n",
      "        432, 627, 589, 295, 595, 465, 646,  34,  38, 383, 162,  57, 538,  64,\n",
      "        477, 613,  85, 605,   8, 213, 510, 293, 265, 261, 210, 481, 356, 408,\n",
      "        323, 583,  75, 528, 336, 621,  43, 235, 529, 568, 180, 114,  36, 364,\n",
      "        405, 620, 144, 351, 168, 472,  20, 120, 518, 177, 397, 142, 191, 278,\n",
      "        649, 299, 447, 463, 601, 519, 527,  56])\n",
      "dice score:0.881001\n",
      "numpy_result/dsb/1/MTGFFDSB4_test_result/gts.npy\n",
      "numpy_result/dsb/1/MTGFFDSB4_test_result/preds.npy\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 130/134 [00:03<00:00, 33.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pq       SQ       DQ     AJI  multi_pq+\n",
      "0.749815 0.848081 0.874492 0.75066   0.744167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:03<00:00, 33.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'dsb'\n",
    "device = 'cuda'\n",
    "split_num = 1\n",
    "\n",
    "import torch\n",
    "import os \n",
    "import numpy as np\n",
    "from Netlib.CDNetlib.tools.augmentation import  MyCenterCrop\n",
    "from Netlib.MTGFFlib.tools.dataset import MtgffDSBdataset\n",
    "from Netlib.MTGFFlib.config import mtgff_config\n",
    "from Netlib.HoVerNetlib.tools.dataset import HoverNetDataset_DSB,Subset\n",
    "\n",
    "arg = mtgff_config.MTGFFDSB4(ds=dataset_name,device=device,ds_num=split_num)\n",
    "net = arg.model(\n",
    "    anchors=arg.anchor_wh.to(arg.device),\n",
    "    use_H_stain = arg.USE_H_STAIN,\n",
    "    backbone=arg.BACKBONE,\n",
    "    bottom_up=arg.BOTTOM_UP,\n",
    "    proposal_generator=arg.PROPAOSAL_GENERATOR,\n",
    "    stride=arg.STRIDE,\n",
    "    rpn_pos_threshold=arg.RPN_POS_THRESHOLD,\n",
    "    rpn_fraction_ratio=arg.RPN_FRACTION_RATIO,\n",
    "    nms_threshold=arg.NMS_THRESHOLD,\n",
    "    pre_nms_k=arg.PRE_NMS_K,\n",
    "    post_nms_k=arg.POST_NMS_K,\n",
    "    use_deform = arg.USE_DEFORM,\n",
    "    roi_head=arg.ROI_HEAD,\n",
    "    box_detection=arg.BOX_DETECTION,\n",
    "    expand=arg.EXPAND,\n",
    "    expand_ratio=arg.EXPAND_RATIO,\n",
    "    use_gt_box=arg.USE_GT_BOX,\n",
    "    roi_resolution=arg.ROI_RESOLUTION,\n",
    "    stage2_max_proposal=arg.STAGE2_MAX_PROPOSAL,\n",
    "    stage2_sample_ratio=arg.STAGE2_SAMPLE_RATIO,\n",
    "    box_weight=arg.BOX_WEIGHT,\n",
    "    roi_pos_threshold=arg.ROI_POS_THRESHOLD,\n",
    "    post_decttion_score_threshold=arg.POST_DETECTION_SCORE_THRESHOLD,\n",
    "    detection_per_img=arg.DETECTION_PER_IMG,\n",
    "    num_classes=arg.NUM_CLASSES,\n",
    "    use_semantic=arg.USE_SEMANTIC,\n",
    "    seg_stride=arg.SEG_STRIDE,\n",
    "    fuse_feature=arg.FUSE_FEATURE\n",
    ")\n",
    "net.load_state_dict(torch.load(arg.load_model_para))\n",
    "net.to(device=device)\n",
    "net.eval()\n",
    "data = MtgffDSBdataset(arg.DATASET_FP,transfs=[MyCenterCrop((256,256))],train=True)\n",
    "\n",
    "preds = np.zeros((0,256,256,2),dtype=np.int32)\n",
    "with torch.no_grad():\n",
    "    for i in arg.TEST_SET_INDEX:\n",
    "        imgs = data[i][0][None].to(device=device)\n",
    "        print(imgs.shape,imgs.max(),imgs.min())\n",
    "        pred, _ = net(imgs)\n",
    "        pred = net.inference(pred,[256,256])\n",
    "        print(pred.shape,pred[0].max(),pred[0].min())\n",
    "        preds = np.concatenate([preds,pred],axis=0)\n",
    "\n",
    "pred_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/gts.npy'\n",
    "gts_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/preds.npy'\n",
    "if not os.path.exists(os.path.dirname(pred_path)):\n",
    "        os.makedirs(os.path.dirname(pred_path))\n",
    "if not os.path.exists(os.path.dirname(gts_path)):\n",
    "        os.makedirs(os.path.dirname(gts_path))\n",
    "\n",
    "import PIL.Image as Image\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "from Netlib.HoVerNetlib.tools.utils import draw_instance_map\n",
    "from Netlib.HoVerNetlib.tools.metric import dice_score\n",
    "\n",
    "def print_metric(pred_path, true_path):\n",
    "        pred =np.load(pred_path)\n",
    "        target = np.load(true_path)\n",
    "        pred = torch.from_numpy(pred.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        target = torch.from_numpy(target.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        dice = dice_score(pred[..., 1], target[..., 1])\n",
    "        print(f\"dice score:{dice:.6f}\")\n",
    "\n",
    "cp = MyCenterCrop((256,256))\n",
    "np.save(pred_path,preds)\n",
    "print(arg.TEST_SET_INDEX)\n",
    "imgs = torch.zeros((0,3,256,256),dtype=torch.float32)\n",
    "gts = np.zeros((0,256,256,2),dtype=np.int32)\n",
    "\n",
    "for i in arg.TEST_SET_INDEX:\n",
    "    img = Image.open(os.path.join('data/DSB2018/train', data.data_dir[i], 'images', data.data_dir[i]+'.png')).convert('RGB')\n",
    "    img = pil_to_tensor(img).float() / 255\n",
    "    img = cp((img))[0]\n",
    "    instances = os.listdir(os.path.join( 'data/DSB2018/train',data.data_dir[i], \"masks\"))\n",
    "    instances.sort()\n",
    "    label = torch.zeros(2, img.shape[1], img.shape[2], dtype=torch.long)\n",
    "    for idx, ins in enumerate(instances):\n",
    "        mask = Image.open(os.path.join(data.train_dir, data.data_dir[i], \"masks\", ins))\n",
    "        mask = pil_to_tensor(mask).bool() * 1\n",
    "        mask = cp((mask))[0]\n",
    "        label[0][label[0]==0] += mask[0][label[0]==0] * (idx+1)\n",
    "        label[1][label[1]==0] += mask[0][label[1]==0].long()\n",
    "\n",
    "    imgs = torch.cat((imgs,img.unsqueeze(0)),0)\n",
    "    gts = np.concatenate((gts,label.permute(1,2,0).unsqueeze(0).cpu().numpy()),axis=0)\n",
    "\n",
    "np.save(gts_path,gts)\n",
    "\n",
    "if not os.path.exists(arg.figure_dir+'/preds'):\n",
    "        print(\"not find the path\")\n",
    "        os.makedirs(arg.figure_dir+'/preds')\n",
    "\n",
    "draw_instance_map(imgs,preds,fp=arg.figure_dir+'/preds')\n",
    "print_metric(pred_path,gts_path)\n",
    "\n",
    "print(pred_path)\n",
    "print(gts_path)\n",
    "print(arg.CLASSES-1)\n",
    "os.system(f'python compute_metric/compute_stats.py --mode=seg_class --pred={pred_path} --true={gts_path} --class_num={arg.CLASSES-1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into memory\n",
      "not find the path\n",
      "dice score:0.737432\n",
      "numpy_result/pannuke/1/MTGFFPanNuke_test_result/gts.npy\n",
      "numpy_result/pannuke/1/MTGFFPanNuke_test_result/preds.npy\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1580/1580 [02:13<00:00, 11.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pq       SQ       DQ      AJI  multi_pq+\n",
      "0.528459 0.704377 0.699264 0.598335   0.443028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'pannuke'\n",
    "device = 'cuda'\n",
    "split_num = 1\n",
    "\n",
    "import torch\n",
    "import os \n",
    "import numpy as np\n",
    "from Netlib.CDNetlib.tools.augmentation import  MyCenterCrop\n",
    "from Netlib.MTGFFlib.tools.dataset import MtgffPannukeDataset\n",
    "from Netlib.MTGFFlib.config import mtgff_config\n",
    "from Netlib.MTGFFlib.model.GeneralizedRCNN import MTGFFNet\n",
    "\n",
    "arg = mtgff_config.MTGFFPanNuke(ds = dataset_name, device = device, ds_num = split_num)\n",
    "net = arg.model(\n",
    "    anchors=arg.anchor_wh.to(arg.device),\n",
    "    use_H_stain = arg.USE_H_STAIN,\n",
    "    backbone=arg.BACKBONE,\n",
    "    bottom_up=arg.BOTTOM_UP,\n",
    "    proposal_generator=arg.PROPAOSAL_GENERATOR,\n",
    "    stride=arg.STRIDE,\n",
    "    rpn_pos_threshold=arg.RPN_POS_THRESHOLD,\n",
    "    rpn_fraction_ratio=arg.RPN_FRACTION_RATIO,\n",
    "    nms_threshold=arg.NMS_THRESHOLD,\n",
    "    pre_nms_k=arg.PRE_NMS_K,\n",
    "    post_nms_k=arg.POST_NMS_K,\n",
    "    use_deform = arg.USE_DEFORM,\n",
    "    roi_head=arg.ROI_HEAD,\n",
    "    box_detection=arg.BOX_DETECTION,\n",
    "    expand=arg.EXPAND,\n",
    "    expand_ratio=arg.EXPAND_RATIO,\n",
    "    use_gt_box=arg.USE_GT_BOX,\n",
    "    roi_resolution=arg.ROI_RESOLUTION,\n",
    "    stage2_max_proposal=arg.STAGE2_MAX_PROPOSAL,\n",
    "    stage2_sample_ratio=arg.STAGE2_SAMPLE_RATIO,\n",
    "    box_weight=arg.BOX_WEIGHT,\n",
    "    roi_pos_threshold=arg.ROI_POS_THRESHOLD,\n",
    "    post_decttion_score_threshold=arg.POST_DETECTION_SCORE_THRESHOLD,\n",
    "    detection_per_img=arg.DETECTION_PER_IMG,\n",
    "    num_classes=arg.NUM_CLASSES,\n",
    "    use_semantic=arg.USE_SEMANTIC,\n",
    "    seg_stride=arg.SEG_STRIDE,\n",
    "    fuse_feature=arg.FUSE_FEATURE\n",
    ")\n",
    "net.load_state_dict(torch.load(arg.load_model_para))\n",
    "net.to(device=device)\n",
    "net.eval()\n",
    "data = MtgffPannukeDataset(arg.ROI_RESOLUTION,transfs=[MyCenterCrop((256,256))],train=False)\n",
    "preds = np.zeros((0,256,256,2))\n",
    "gts = np.zeros((0,256,256,2))\n",
    "imgs = torch.zeros(0,3,256,256)\n",
    "with torch.no_grad():\n",
    "    for i in arg.TEST_SET_INDEX:\n",
    "        img = data[i][0][None].to(device=device)\n",
    "        imgs = torch.cat([imgs,img.cpu()],dim=0)\n",
    "        label = data[i][1][None].permute(0,2,3,1).numpy()\n",
    "        gts = np.concatenate([gts,label],axis=0)\n",
    "        pred, _ = net(img)\n",
    "        pred = net.inference(pred,[256,256])\n",
    "        preds = np.concatenate([preds,pred],axis=0)\n",
    "pred_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/gts.npy'\n",
    "gts_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/preds.npy'\n",
    "from Netlib.HoVerNetlib.tools.utils import draw_instance_map\n",
    "from Netlib.HoVerNetlib.tools.metric import dice_score\n",
    "def print_metric(pred_path, true_path):\n",
    "        pred =np.load(pred_path)\n",
    "        target = np.load(true_path)\n",
    "        pred = torch.from_numpy(pred.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        target = torch.from_numpy(target.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        dice = dice_score(pred[..., 1], target[..., 1])\n",
    "        print(f\"dice score:{dice:.6f}\")\n",
    "#获取文件目录中的父目录路径：\n",
    "if not os.path.exists(os.path.dirname(pred_path)):\n",
    "        os.makedirs(os.path.dirname(pred_path))\n",
    "if not os.path.exists(os.path.dirname(gts_path)):\n",
    "        os.makedirs(os.path.dirname(gts_path))\n",
    "\n",
    "np.save(pred_path,preds)\n",
    "np.save(gts_path,gts)\n",
    "\n",
    "if not os.path.exists(arg.figure_dir+'/preds'):\n",
    "        print(\"not find the path\")\n",
    "        os.makedirs(arg.figure_dir+'/preds')\n",
    "draw_instance_map(imgs,preds,fp=arg.figure_dir+'/preds')\n",
    "print_metric(pred_path,gts_path)\n",
    "\n",
    "print(pred_path)\n",
    "print(gts_path)\n",
    "print(arg.CLASSES-1)\n",
    "os.system(f'python compute_metric/compute_stats.py --mode=seg_class --pred={pred_path} --true={gts_path} --class_num={arg.CLASSES-1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model_para/conic/1/MTGFFConic/best.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2660/1148780514.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mfuse_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFUSE_FEATURE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m )\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_para\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model_para/conic/1/MTGFFConic/best.pth'"
     ]
    }
   ],
   "source": [
    "dataset_name = 'conic'\n",
    "device = 'cuda'\n",
    "split_num = 1\n",
    "\n",
    "import torch\n",
    "import os \n",
    "import numpy as np\n",
    "from Netlib.CDNetlib.tools.augmentation import  MyCenterCrop\n",
    "from Netlib.MTGFFlib.tools.dataset import MtgffConicDataset\n",
    "from Netlib.MTGFFlib.config import mtgff_config\n",
    "from Netlib.MTGFFlib.model.GeneralizedRCNN import MTGFFNet\n",
    "\n",
    "arg = mtgff_config.MTGFFConic(ds = dataset_name, device = device, ds_num = split_num)\n",
    "net = arg.model(\n",
    "    anchors=arg.anchor_wh.to(arg.device),\n",
    "    use_H_stain = arg.USE_H_STAIN,\n",
    "    backbone=arg.BACKBONE,\n",
    "    bottom_up=arg.BOTTOM_UP,\n",
    "    proposal_generator=arg.PROPAOSAL_GENERATOR,\n",
    "    stride=arg.STRIDE,\n",
    "    rpn_pos_threshold=arg.RPN_POS_THRESHOLD,\n",
    "    rpn_fraction_ratio=arg.RPN_FRACTION_RATIO,\n",
    "    nms_threshold=arg.NMS_THRESHOLD,\n",
    "    pre_nms_k=arg.PRE_NMS_K,\n",
    "    post_nms_k=arg.POST_NMS_K,\n",
    "    use_deform = arg.USE_DEFORM,\n",
    "    roi_head=arg.ROI_HEAD,\n",
    "    box_detection=arg.BOX_DETECTION,\n",
    "    expand=arg.EXPAND,\n",
    "    expand_ratio=arg.EXPAND_RATIO,\n",
    "    use_gt_box=arg.USE_GT_BOX,\n",
    "    roi_resolution=arg.ROI_RESOLUTION,\n",
    "    stage2_max_proposal=arg.STAGE2_MAX_PROPOSAL,\n",
    "    stage2_sample_ratio=arg.STAGE2_SAMPLE_RATIO,\n",
    "    box_weight=arg.BOX_WEIGHT,\n",
    "    roi_pos_threshold=arg.ROI_POS_THRESHOLD,\n",
    "    post_decttion_score_threshold=arg.POST_DETECTION_SCORE_THRESHOLD,\n",
    "    detection_per_img=arg.DETECTION_PER_IMG,\n",
    "    num_classes=arg.NUM_CLASSES,\n",
    "    use_semantic=arg.USE_SEMANTIC,\n",
    "    seg_stride=arg.SEG_STRIDE,\n",
    "    fuse_feature=arg.FUSE_FEATURE\n",
    ")\n",
    "net.load_state_dict(torch.load(arg.load_model_para))\n",
    "net.to(device=device)\n",
    "net.eval()\n",
    "data = MtgffConicDataset(arg.ROI_RESOLUTION,transfs=[MyCenterCrop((256,256))],train=False)\n",
    "preds = np.zeros((0,256,256,2))\n",
    "gts = np.zeros((0,256,256,2))\n",
    "imgs = torch.zeros(0,3,256,256)\n",
    "with torch.no_grad():\n",
    "    for i in arg.TEST_SET_INDEX:\n",
    "        img = data[i][0][None].to(device=device)\n",
    "        imgs = torch.cat([imgs,img.cpu()],dim=0)\n",
    "        label = data[i][1][None].permute(0,2,3,1).numpy()\n",
    "        gts = np.concatenate([gts,label],axis=0)\n",
    "        pred, _ = net(img)\n",
    "        pred = net.inference(pred,[256,256])\n",
    "        preds = np.concatenate([preds,pred],axis=0)\n",
    "pred_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/gts.npy'\n",
    "gts_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/preds.npy'\n",
    "from Netlib.HoVerNetlib.tools.utils import draw_instance_map\n",
    "from Netlib.HoVerNetlib.tools.metric import dice_score\n",
    "def print_metric(pred_path, true_path):\n",
    "        pred =np.load(pred_path)\n",
    "        target = np.load(true_path)\n",
    "        pred = torch.from_numpy(pred.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        target = torch.from_numpy(target.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        dice = dice_score(pred[..., 1], target[..., 1])\n",
    "        print(f\"dice score:{dice:.6f}\")\n",
    "#获取文件目录中的父目录路径：\n",
    "if not os.path.exists(os.path.dirname(pred_path)):\n",
    "        os.makedirs(os.path.dirname(pred_path))\n",
    "if not os.path.exists(os.path.dirname(gts_path)):\n",
    "        os.makedirs(os.path.dirname(gts_path))\n",
    "\n",
    "np.save(pred_path,preds)\n",
    "np.save(gts_path,gts)\n",
    "\n",
    "if not os.path.exists(arg.figure_dir+'/preds'):\n",
    "        print(\"not find the path\")\n",
    "        os.makedirs(arg.figure_dir+'/preds')\n",
    "draw_instance_map(imgs,preds,fp=arg.figure_dir+'/preds')\n",
    "print_metric(pred_path,gts_path)\n",
    "\n",
    "print(pred_path)\n",
    "print(gts_path)\n",
    "print(arg.CLASSES-1)\n",
    "os.system(f'python compute_metric/compute_stats.py --mode=seg_class --pred={pred_path} --true={gts_path} --class_num={arg.CLASSES-1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
