{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into memory\n",
      "Finishing loading data\n",
      "dice score:0.756995\n",
      "numpy_result/monuseg/1/MrcnnMonuSeg_test_result/gts.npy\n",
      "numpy_result/monuseg/1/MrcnnMonuSeg_test_result/preds.npy\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:04<00:00, 10.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pq       SQ       DQ      AJI  multi_pq+\n",
      "0.505399 0.716157 0.703389 0.534207   0.515254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'monuseg'\n",
    "device = 'cuda'\n",
    "split_num = 1\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from Netlib.CDNetlib.tools.augmentation import MyCenterCrop\n",
    "from Netlib.MaskRCNNlib.tools.dataset import MonusegDataset\n",
    "from Netlib.MaskRCNNlib.Config import mrcnn_configs\n",
    "from Netlib.MaskRCNNlib.model.GeneralizedRCNN import MRCNN\n",
    "\n",
    "arg = mrcnn_configs.MrcnnMonuSeg(ds = dataset_name, device = device, ds_num = split_num)\n",
    "net = arg.model(\n",
    "            anchors=arg.anchor_wh.to(arg.device),\n",
    "            backbone=arg.BACKBONE,\n",
    "            bottom_up=arg.BOTTOM_UP,\n",
    "            proposal_generator=arg.PROPAOSAL_GENERATOR,\n",
    "            stride=arg.STRIDE,\n",
    "            rpn_pos_threshold=arg.RPN_POS_THRESHOLD,\n",
    "            rpn_fraction_ratio=arg.RPN_FRACTION_RATIO,\n",
    "            nms_threshold=arg.NMS_THRESHOLD,\n",
    "            pre_nms_k=arg.PRE_NMS_K,\n",
    "            post_nms_k=arg.POST_NMS_K,\n",
    "            roi_head=arg.ROI_HEAD,\n",
    "            box_detection=arg.BOX_DETECTION,\n",
    "            expand=arg.EXPAND,\n",
    "            expand_ratio=arg.EXPAND_RATIO,\n",
    "            use_gt_box=arg.USE_GT_BOX,\n",
    "            roi_resolution=arg.ROI_RESOLUTION,\n",
    "            stage2_max_proposal=arg.STAGE2_MAX_PROPOSAL,\n",
    "            stage2_sample_ratio=arg.STAGE2_SAMPLE_RATIO,\n",
    "            box_weight=arg.BOX_WEIGHT,\n",
    "            roi_pos_threshold=arg.ROI_POS_THRESHOLD,\n",
    "            post_decttion_score_threshold=arg.POST_DETECTION_SCORE_THRESHOLD,\n",
    "            detection_per_img=arg.DETECTION_PER_IMG,\n",
    "            num_classes=arg.NUM_CLASSES,\n",
    "            use_semantic=arg.USE_SEMANTIC,\n",
    "            seg_stride=arg.SEG_STRIDE,\n",
    "            fuse_feature=arg.FUSE_FEATURE,\n",
    "        ).to(device=arg.device)\n",
    "net.load_state_dict(torch.load(arg.load_model_para))\n",
    "net.to(device=device)\n",
    "net.eval()\n",
    "data = MonusegDataset(arg.ROI_RESOLUTION,[MyCenterCrop((256,256))],train=False)\n",
    "preds = np.zeros((0,256,256,2))\n",
    "for i in range(len(data)):\n",
    "    imgs = data[i][0].to(device).unsqueeze(0)\n",
    "    pred, _ = net(imgs)\n",
    "    pred = net.inference(pred,[256,256])\n",
    "    preds = np.concatenate([preds,pred],axis=0)\n",
    "\n",
    "\n",
    "pred_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/gts.npy'\n",
    "gts_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/preds.npy'\n",
    "from Netlib.HoVerNetlib.tools.utils import draw_instance_map\n",
    "from Netlib.HoVerNetlib.tools.metric import dice_score\n",
    "\n",
    "def print_metric(pred_path, true_path):\n",
    "        pred =np.load(pred_path)\n",
    "        target = np.load(true_path)\n",
    "        pred = torch.from_numpy(pred.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        target = torch.from_numpy(target.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        dice = dice_score(pred[..., 1], target[..., 1])\n",
    "        print(f\"dice score:{dice:.6f}\")\n",
    "\n",
    "#获取文件目录中的父目录路径：\n",
    "if not os.path.exists(os.path.dirname(pred_path)):\n",
    "        os.makedirs(os.path.dirname(pred_path))\n",
    "if not os.path.exists(os.path.dirname(gts_path)):\n",
    "        os.makedirs(os.path.dirname(gts_path))\n",
    "\n",
    "np.save(pred_path,preds)\n",
    "cp = MyCenterCrop((256,256))\n",
    "\n",
    "gts = cp((data.labels))[0].permute(0,2,3,1).cpu().numpy()\n",
    "np.save(gts_path,gts)\n",
    "imgs = cp((data.imgs))[0]\n",
    "\n",
    "if not os.path.exists(arg.figure_dir+'/preds'):\n",
    "        print(\"not find the path\")\n",
    "        os.makedirs(arg.figure_dir+'/preds')\n",
    "\n",
    "draw_instance_map(imgs,preds,fp=arg.figure_dir+'/preds')\n",
    "print_metric(pred_path,gts_path)\n",
    "\n",
    "print(pred_path)\n",
    "print(gts_path)\n",
    "print(arg.CLASSES-1)\n",
    "os.system(f'python compute_metric/compute_stats.py --mode=seg_class --pred={pred_path} --true={gts_path} --class_num={arg.CLASSES-1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into memory\n",
      "not find the path\n",
      "dice score:0.826880\n",
      "numpy_result/cpm/1/MrcnnCPM_test_result/gts.npy\n",
      "numpy_result/cpm/1/MrcnnCPM_test_result/preds.npy\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:02<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pq       SQ      DQ      AJI  multi_pq+\n",
      "0.609784 0.763688 0.79655 0.642788   0.610986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'cpm'\n",
    "device = 'cuda'\n",
    "split_num = 1\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from Netlib.CDNetlib.tools.augmentation import MyCenterCrop\n",
    "from Netlib.MaskRCNNlib.tools.dataset import CPMDataset\n",
    "from Netlib.MaskRCNNlib.Config import mrcnn_configs\n",
    "from Netlib.MaskRCNNlib.model.GeneralizedRCNN import MRCNN\n",
    "\n",
    "arg = mrcnn_configs.MrcnnCPM(ds = dataset_name, device = device, ds_num = split_num)\n",
    "net = arg.model(\n",
    "            anchors=arg.anchor_wh.to(arg.device),\n",
    "            backbone=arg.BACKBONE,\n",
    "            bottom_up=arg.BOTTOM_UP,\n",
    "            proposal_generator=arg.PROPAOSAL_GENERATOR,\n",
    "            stride=arg.STRIDE,\n",
    "            rpn_pos_threshold=arg.RPN_POS_THRESHOLD,\n",
    "            rpn_fraction_ratio=arg.RPN_FRACTION_RATIO,\n",
    "            nms_threshold=arg.NMS_THRESHOLD,\n",
    "            pre_nms_k=arg.PRE_NMS_K,\n",
    "            post_nms_k=arg.POST_NMS_K,\n",
    "            roi_head=arg.ROI_HEAD,\n",
    "            box_detection=arg.BOX_DETECTION,\n",
    "            expand=arg.EXPAND,\n",
    "            expand_ratio=arg.EXPAND_RATIO,\n",
    "            use_gt_box=arg.USE_GT_BOX,\n",
    "            roi_resolution=arg.ROI_RESOLUTION,\n",
    "            stage2_max_proposal=arg.STAGE2_MAX_PROPOSAL,\n",
    "            stage2_sample_ratio=arg.STAGE2_SAMPLE_RATIO,\n",
    "            box_weight=arg.BOX_WEIGHT,\n",
    "            roi_pos_threshold=arg.ROI_POS_THRESHOLD,\n",
    "            post_decttion_score_threshold=arg.POST_DETECTION_SCORE_THRESHOLD,\n",
    "            detection_per_img=arg.DETECTION_PER_IMG,\n",
    "            num_classes=arg.NUM_CLASSES,\n",
    "            use_semantic=arg.USE_SEMANTIC,\n",
    "            seg_stride=arg.SEG_STRIDE,\n",
    "            fuse_feature=arg.FUSE_FEATURE,\n",
    "        ).to(device=arg.device)\n",
    "net.load_state_dict(torch.load(arg.load_model_para))\n",
    "net.to(device=device)\n",
    "net.eval()\n",
    "data = CPMDataset(arg.DATASET_FP,arg.ROI_RESOLUTION,[MyCenterCrop((256,256))],train=False)\n",
    "preds = np.zeros((0,256,256,2))\n",
    "for i in range(len(data)):\n",
    "    imgs = data[i][0].to(device).unsqueeze(0)\n",
    "    pred, _ = net(imgs)\n",
    "    pred = net.inference(pred,[256,256])\n",
    "    preds = np.concatenate([preds,pred],axis=0)\n",
    "    \n",
    "pred_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/gts.npy'\n",
    "gts_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/preds.npy'\n",
    "from Netlib.HoVerNetlib.tools.utils import draw_instance_map\n",
    "from Netlib.HoVerNetlib.tools.metric import dice_score\n",
    "\n",
    "def print_metric(pred_path, true_path):\n",
    "        pred =np.load(pred_path)\n",
    "        target = np.load(true_path)\n",
    "        pred = torch.from_numpy(pred.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        target = torch.from_numpy(target.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        dice = dice_score(pred[..., 1], target[..., 1])\n",
    "        print(f\"dice score:{dice:.6f}\")\n",
    "\n",
    "#获取文件目录中的父目录路径：\n",
    "if not os.path.exists(os.path.dirname(pred_path)):\n",
    "        os.makedirs(os.path.dirname(pred_path))\n",
    "if not os.path.exists(os.path.dirname(gts_path)):\n",
    "        os.makedirs(os.path.dirname(gts_path))\n",
    "\n",
    "np.save(pred_path,preds)\n",
    "cp = MyCenterCrop((256,256))\n",
    "\n",
    "gts = np.load('data/cpm17/test/labels.npy')\n",
    "np.save(gts_path,gts)\n",
    "imgs = torch.load('data/cpm17/test/imgs.pt')\n",
    "\n",
    "if not os.path.exists(arg.figure_dir+'/preds'):\n",
    "        print(\"not find the path\")\n",
    "        os.makedirs(arg.figure_dir+'/preds')\n",
    "\n",
    "draw_instance_map(imgs,preds,fp=arg.figure_dir+'/preds')\n",
    "print_metric(pred_path,gts_path)\n",
    "\n",
    "print(pred_path)\n",
    "print(gts_path)\n",
    "print(arg.CLASSES-1)\n",
    "os.system(f'python compute_metric/compute_stats.py --mode=seg_class --pred={pred_path} --true={gts_path} --class_num={arg.CLASSES-1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into memory\n",
      "tensor([659, 439, 334, 558, 271, 414, 195, 652,  23, 409, 292, 111, 287, 324,\n",
      "        592, 390, 612, 648, 340, 615, 660, 108,   2, 223, 134, 495,  46,  15,\n",
      "        275, 498, 216, 132, 500, 163, 123, 452,  51, 341, 376, 370, 655,  24,\n",
      "        211,  80, 526, 496, 446, 385, 173, 548, 471, 561, 209, 305,  37, 551,\n",
      "        247, 588, 176, 604, 233, 189,  68, 333, 515,  42, 208, 139, 194,  69,\n",
      "        432, 627, 589, 295, 595, 465, 646,  34,  38, 383, 162,  57, 538,  64,\n",
      "        477, 613,  85, 605,   8, 213, 510, 293, 265, 261, 210, 481, 356, 408,\n",
      "        323, 583,  75, 528, 336, 621,  43, 235, 529, 568, 180, 114,  36, 364,\n",
      "        405, 620, 144, 351, 168, 472,  20, 120, 518, 177, 397, 142, 191, 278,\n",
      "        649, 299, 447, 463, 601, 519, 527,  56])\n",
      "not find the path\n",
      "dice score:0.865691\n",
      "numpy_result/dsb/1/MrcnnDSB_test_result/gts.npy\n",
      "numpy_result/dsb/1/MrcnnDSB_test_result/preds.npy\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:05<00:00, 25.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pq       SQ       DQ      AJI  multi_pq+\n",
      "0.703093 0.820552 0.845341 0.710505   0.681118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'dsb'\n",
    "device = 'cuda'\n",
    "split_num = 1\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from Netlib.CDNetlib.tools.augmentation import MyCenterCrop\n",
    "from Netlib.MaskRCNNlib.tools.dataset import DSBDataset\n",
    "from Netlib.MaskRCNNlib.Config import mrcnn_configs\n",
    "from Netlib.MaskRCNNlib.model.GeneralizedRCNN import MRCNN\n",
    "\n",
    "arg = mrcnn_configs.MrcnnDSB(ds=dataset_name,device=device,ds_num=split_num)\n",
    "net = arg.model(\n",
    "            anchors=arg.anchor_wh.to(arg.device),\n",
    "            backbone=arg.BACKBONE,\n",
    "            bottom_up=arg.BOTTOM_UP,\n",
    "            proposal_generator=arg.PROPAOSAL_GENERATOR,\n",
    "            stride=arg.STRIDE,\n",
    "            rpn_pos_threshold=arg.RPN_POS_THRESHOLD,\n",
    "            rpn_fraction_ratio=arg.RPN_FRACTION_RATIO,\n",
    "            nms_threshold=arg.NMS_THRESHOLD,\n",
    "            pre_nms_k=arg.PRE_NMS_K,\n",
    "            post_nms_k=arg.POST_NMS_K,\n",
    "            roi_head=arg.ROI_HEAD,\n",
    "            box_detection=arg.BOX_DETECTION,\n",
    "            expand=arg.EXPAND,\n",
    "            expand_ratio=arg.EXPAND_RATIO,\n",
    "            use_gt_box=arg.USE_GT_BOX,\n",
    "            roi_resolution=arg.ROI_RESOLUTION,\n",
    "            stage2_max_proposal=arg.STAGE2_MAX_PROPOSAL,\n",
    "            stage2_sample_ratio=arg.STAGE2_SAMPLE_RATIO,\n",
    "            box_weight=arg.BOX_WEIGHT,\n",
    "            roi_pos_threshold=arg.ROI_POS_THRESHOLD,\n",
    "            post_decttion_score_threshold=arg.POST_DETECTION_SCORE_THRESHOLD,\n",
    "            detection_per_img=arg.DETECTION_PER_IMG,\n",
    "            num_classes=arg.NUM_CLASSES,\n",
    "            use_semantic=arg.USE_SEMANTIC,\n",
    "            seg_stride=arg.SEG_STRIDE,\n",
    "            fuse_feature=arg.FUSE_FEATURE,\n",
    "        ).to(device=arg.device)\n",
    "net.load_state_dict(torch.load(arg.load_model_para))\n",
    "net.to(device=device)\n",
    "net.eval()\n",
    "data = DSBDataset(arg.DATASET_FP,transfs=[MyCenterCrop((256,256))],train=True)\n",
    "preds = np.zeros((0,256,256,2),dtype=np.int32)\n",
    "\n",
    "for i in arg.TEST_SET_INDEX:\n",
    "    img = data[i][0].unsqueeze(0).to(device)\n",
    "    pred, _ = net(img)\n",
    "    pred = net.inference(pred,[256,256]) \n",
    "    preds = np.concatenate([preds,pred],axis=0)\n",
    "\n",
    "pred_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/gts.npy'\n",
    "gts_path = os.path.join('numpy_result',arg.TEST_RESULT_DIR)+'/preds.npy'\n",
    "if not os.path.exists(os.path.dirname(pred_path)):\n",
    "        os.makedirs(os.path.dirname(pred_path))\n",
    "if not os.path.exists(os.path.dirname(gts_path)):\n",
    "        os.makedirs(os.path.dirname(gts_path))\n",
    "\n",
    "import PIL.Image as Image\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "from Netlib.HoVerNetlib.tools.utils import draw_instance_map\n",
    "from Netlib.HoVerNetlib.tools.metric import dice_score\n",
    "\n",
    "def print_metric(pred_path, true_path):\n",
    "        pred =np.load(pred_path)\n",
    "        target = np.load(true_path)\n",
    "        pred = torch.from_numpy(pred.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        target = torch.from_numpy(target.astype(np.int16)).long() # [N, 256, 256, 2]\n",
    "        dice = dice_score(pred[..., 1], target[..., 1])\n",
    "        print(f\"dice score:{dice:.6f}\")\n",
    "cp = MyCenterCrop((256,256))\n",
    "np.save(pred_path,preds)\n",
    "print(arg.TEST_SET_INDEX)\n",
    "imgs = torch.zeros((0,3,256,256),dtype=torch.float32)\n",
    "gts = np.zeros((0,256,256,2),dtype=np.int32)\n",
    "\n",
    "for i in arg.TEST_SET_INDEX:\n",
    "    img = Image.open(os.path.join('data/DSB2018/train', data.data_dir[i], 'images', data.data_dir[i]+'.png')).convert('RGB')\n",
    "    img = pil_to_tensor(img).float() / 255\n",
    "    img = cp((img))[0]\n",
    "    instances = os.listdir(os.path.join( 'data/DSB2018/train',data.data_dir[i], \"masks\"))\n",
    "    instances.sort()\n",
    "    label = torch.zeros(2, img.shape[1], img.shape[2], dtype=torch.long)\n",
    "    for idx, ins in enumerate(instances):\n",
    "        mask = Image.open(os.path.join(data.train_dir, data.data_dir[i], \"masks\", ins))\n",
    "        mask = pil_to_tensor(mask).bool() * 1\n",
    "        mask = cp((mask))[0]\n",
    "        label[0][label[0]==0] += mask[0][label[0]==0] * (idx+1)\n",
    "        label[1][label[1]==0] += mask[0][label[1]==0].long()\n",
    "\n",
    "    imgs = torch.cat((imgs,img.unsqueeze(0)),0)\n",
    "    gts = np.concatenate((gts,label.permute(1,2,0).unsqueeze(0).cpu().numpy()),axis=0)\n",
    "\n",
    "np.save(gts_path,gts)\n",
    "\n",
    "if not os.path.exists(arg.figure_dir+'/preds'):\n",
    "        print(\"not find the path\")\n",
    "        os.makedirs(arg.figure_dir+'/preds')\n",
    "\n",
    "draw_instance_map(imgs,preds,fp=arg.figure_dir+'/preds')\n",
    "print_metric(pred_path,gts_path)\n",
    "\n",
    "print(pred_path)\n",
    "print(gts_path)\n",
    "print(arg.CLASSES-1)\n",
    "os.system(f'python compute_metric/compute_stats.py --mode=seg_class --pred={pred_path} --true={gts_path} --class_num={arg.CLASSES-1}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
